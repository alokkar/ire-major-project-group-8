{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1980,
     "status": "ok",
     "timestamp": 1547340412889,
     "user": {
      "displayName": "Alison Ribeiro",
      "photoUrl": "https://lh6.googleusercontent.com/-p2L5zKSs9Oc/AAAAAAAAAAI/AAAAAAAAAEE/PzwO-PqNro8/s64/photo.jpg",
      "userId": "16421844834226782203"
     },
     "user_tz": 120
    },
    "id": "QL28WSHoBsfp",
    "outputId": "f22d55d4-e94a-4a41-e258-28a2a2077a73"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D, Reshape\n",
    "from keras.layers import Input, concatenate, Dropout\n",
    "from keras.layers import Embedding, Concatenate\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s3Dnnk8FF4j"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Dataset/transl_aug/data_degree_4.tsv', delimiter='\\t',encoding='utf-8')\n",
    "dev = pd.read_csv('./dev_en.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrslbThJCeSY"
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    tweet = re.sub('@(\\\\w{1,15})\\b', '', tweet)\n",
    "    tweet = tweet.replace(\"via \", \"\")\n",
    "    tweet = tweet.replace(\"RT \", \"\")\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "    \n",
    "def clean_url(tweet):\n",
    "    tweet = re.sub('http\\\\S+', '', tweet, flags=re.MULTILINE)   \n",
    "    return tweet\n",
    "    \n",
    "def remove_stop_words(tweet):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    stops.update(['.',',','\"',\"'\",'?',':',';','(',')','[',']','{','}'])\n",
    "    toks = [tok for tok in tweet if not tok in stops and len(tok) >= 3]\n",
    "    return toks\n",
    "    \n",
    "def stemming_tweets(tweet):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in tweet]\n",
    "    return stemmed_words\n",
    "\n",
    "def remove_number(tweet):\n",
    "    newTweet = re.sub('\\\\d+', '', tweet)\n",
    "    return newTweet\n",
    "\n",
    "def remove_hashtags(tweet):\n",
    "    result = ''\n",
    "\n",
    "    for word in tweet.split():\n",
    "        if word.startswith('#') or word.startswith('@'):\n",
    "            result += word[1:]\n",
    "            result += ' '\n",
    "        else:\n",
    "            result += word\n",
    "            result += ' '\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/saurabh.ramola/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDsnLDRQGl71"
   },
   "outputs": [],
   "source": [
    "def preprocessing(tweet, swords = True, url = True, stemming = False, ctweets = True, number = True, hashtag = True):\n",
    "\n",
    "    if ctweets:\n",
    "        tweet = clean_tweets(tweet)\n",
    "\n",
    "    if url:\n",
    "        tweet = clean_url(tweet)\n",
    "\n",
    "    if hashtag:\n",
    "        tweet = remove_hashtags(tweet)\n",
    "    \n",
    "    twtk = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "\n",
    "    if number:\n",
    "        tweet = remove_number(tweet)\n",
    "    \n",
    "    tokens = [w.lower() for w in twtk.tokenize(tweet) if w != \"\" and w is not None]\n",
    "\n",
    "    if swords:\n",
    "        tokens = remove_stop_words(tokens)\n",
    "\n",
    "    if stemming:\n",
    "        tokens = stemming_tweets(tokens)\n",
    "\n",
    "    text = \" \".join(tokens)\n",
    "#     print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SunHFjyyFLR3"
   },
   "outputs": [],
   "source": [
    "train_text  = train['text'].map(lambda x: preprocessing(x, swords = True, url = True, stemming = False, ctweets = True, number = False, hashtag = False))\n",
    "y_train  = train['HS']\n",
    "id_train = train['id']\n",
    "ag_train = train['TR']\n",
    "test_text  = dev['text'].map(lambda x: preprocessing(x, swords = True, url = True, stemming = False, ctweets = True, number = False, hashtag = False))\n",
    "y_test  = dev['HS']\n",
    "id_test = dev['id']\n",
    "ag_test = dev['TR']\n",
    "\n",
    "data = np.concatenate((train_text, test_text), axis=0)\n",
    "classes = np.concatenate((y_train, y_test), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "classes = []\n",
    "for index,word in enumerate(train_text):\n",
    "    if y_train[index]:\n",
    "        texts.append(word)\n",
    "        if ag_train[index]:\n",
    "            classes.append(0)\n",
    "        else:\n",
    "            classes.append(1)\n",
    "\n",
    "train_text = texts\n",
    "y_train = classes\n",
    "\n",
    "texts = []\n",
    "classes = []\n",
    "for index,word in enumerate(test_text):\n",
    "    if y_test[index]:\n",
    "        texts.append(word)\n",
    "        if ag_test[index]:\n",
    "            classes.append(0)\n",
    "        else:\n",
    "            classes.append(1)\n",
    "\n",
    "test_text = texts\n",
    "y_test = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15132, 427)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_text),len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for x in y_train:\n",
    "    if x==0:\n",
    "        count1+=1\n",
    "    else:\n",
    "        count2+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5364, 9768)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count1,count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dF4yXFPKoA1g"
   },
   "outputs": [],
   "source": [
    "def word_embeddings(word_index, num_words, word_embedding_dim):\n",
    "    embeddings_index = {}\n",
    "    \n",
    "    f = open('./glove.6B.300d.txt', 'r', encoding='utf-8')\n",
    "    \n",
    "    for line in tqdm(f):\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "    matrix = np.zeros((num_words, word_embedding_dim))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        \n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            matrix[i] = embedding_vector\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyUJRLIQoSVj"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "max_features = 20000\n",
    "maxlen = 40\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "filter_sizes = [2,3]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "X = tokenizer.texts_to_sequences(train_text)\n",
    "Y = tokenizer.texts_to_sequences(test_text)\n",
    "\n",
    "tweets = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(Y, maxlen=maxlen)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "num_words = min(max_features, len(word_index) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvKdMmt8wn-J"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(tweets, y_train, test_size=0.1, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64875,
     "status": "ok",
     "timestamp": 1547340476319,
     "user": {
      "displayName": "Alison Ribeiro",
      "photoUrl": "https://lh6.googleusercontent.com/-p2L5zKSs9Oc/AAAAAAAAAAI/AAAAAAAAAEE/PzwO-PqNro8/s64/photo.jpg",
      "userId": "16421844834226782203"
     },
     "user_tz": 120
    },
    "id": "3O5IjISOoGAV",
    "outputId": "66204646-f601-46ff-9552-9d4948350819"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:35, 11158.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "embedding_matrix = word_embeddings(word_index, num_words, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saurabh.ramola/IRE_MP/venv/lib/python3.5/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 781
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60335,
     "status": "ok",
     "timestamp": 1547340652057,
     "user": {
      "displayName": "Alison Ribeiro",
      "photoUrl": "https://lh6.googleusercontent.com/-p2L5zKSs9Oc/AAAAAAAAAAI/AAAAAAAAAEE/PzwO-PqNro8/s64/photo.jpg",
      "userId": "16421844834226782203"
     },
     "user_tz": 120
    },
    "id": "pTZGv8lcWGIU",
    "outputId": "691014f5-fa16-4a7c-ab97-ac8b84fd74bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 40, 300)      4007100     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 40, 300, 1)   0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 39, 1, 512)   307712      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 38, 1, 512)   461312      reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 512)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2, 1, 512)    0           max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1024)         0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          524800      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            513         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,301,437\n",
      "Trainable params: 5,301,437\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tweet_input = Input(shape=(maxlen,), dtype='int32')\n",
    "\n",
    "embedding = Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=True)(tweet_input)\n",
    "\n",
    "reshape = Reshape((maxlen, embedding_dim, 1))(embedding)\n",
    "\n",
    "cnn1 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embedding_dim), padding='valid', kernel_initializer='normal', activation='tanh')(reshape)\n",
    "\n",
    "max1 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')(cnn1)\n",
    "\n",
    "cnn2 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embedding_dim), padding='valid', kernel_initializer='normal', activation='tanh')(reshape)\n",
    "\n",
    "max2 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')(cnn2)\n",
    "\n",
    "\n",
    "concatenated_tensor = Concatenate(axis=1)([max1, max2])\n",
    "\n",
    "flatten = Flatten()(concatenated_tensor)\n",
    "\n",
    "dropout = Dropout(drop)(flatten)\n",
    "\n",
    "dens = Dense(num_filters, activation='relu')(dropout)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dens)\n",
    "\n",
    "model = Model(inputs=tweet_input, outputs=output)\n",
    "\n",
    "opt = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.01)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13618 samples, validate on 1514 samples\n",
      "Epoch 1/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.4505 - acc: 0.8199 - val_loss: 0.2956 - val_acc: 0.8692\n",
      "Epoch 2/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.2589 - acc: 0.8935 - val_loss: 0.2428 - val_acc: 0.8983\n",
      "Epoch 3/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.1870 - acc: 0.9255 - val_loss: 0.2280 - val_acc: 0.9122\n",
      "Epoch 4/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.1411 - acc: 0.9449 - val_loss: 0.2170 - val_acc: 0.9115\n",
      "Epoch 5/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.1119 - acc: 0.9590 - val_loss: 0.1954 - val_acc: 0.9260\n",
      "Epoch 6/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0913 - acc: 0.9668 - val_loss: 0.1868 - val_acc: 0.9287\n",
      "Epoch 7/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0777 - acc: 0.9719 - val_loss: 0.1868 - val_acc: 0.9300\n",
      "Epoch 8/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0660 - acc: 0.9778 - val_loss: 0.1802 - val_acc: 0.9326\n",
      "Epoch 9/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0553 - acc: 0.9819 - val_loss: 0.1947 - val_acc: 0.9326\n",
      "Epoch 10/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0537 - acc: 0.9820 - val_loss: 0.1803 - val_acc: 0.9320\n",
      "Epoch 11/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0426 - acc: 0.9868 - val_loss: 0.1853 - val_acc: 0.9339\n",
      "Epoch 12/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0410 - acc: 0.9865 - val_loss: 0.1765 - val_acc: 0.9359\n",
      "Epoch 13/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0364 - acc: 0.9888 - val_loss: 0.1850 - val_acc: 0.9339\n",
      "Epoch 14/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0364 - acc: 0.9883 - val_loss: 0.1803 - val_acc: 0.9379\n",
      "Epoch 15/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0324 - acc: 0.9893 - val_loss: 0.1814 - val_acc: 0.9379\n",
      "Epoch 16/20\n",
      "13618/13618 [==============================] - 24s 2ms/step - loss: 0.0301 - acc: 0.9899 - val_loss: 0.1787 - val_acc: 0.9406\n",
      "Epoch 17/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0302 - acc: 0.9896 - val_loss: 0.1810 - val_acc: 0.9386\n",
      "Epoch 18/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0267 - acc: 0.9922 - val_loss: 0.1891 - val_acc: 0.9386\n",
      "Epoch 19/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0250 - acc: 0.9924 - val_loss: 0.1977 - val_acc: 0.9373\n",
      "Epoch 20/20\n",
      "13618/13618 [==============================] - 23s 2ms/step - loss: 0.0227 - acc: 0.9927 - val_loss: 0.1899 - val_acc: 0.9392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x147bdf01a898>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=4, verbose=1)\n",
    "mcp_save = ModelCheckpoint('./tr_mdl_wts.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
    "callbacks_list = [mcp_save]\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=20, shuffle=True, callbacks = callbacks_list,validation_data=(x_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1547340661156,
     "user": {
      "displayName": "Alison Ribeiro",
      "photoUrl": "https://lh6.googleusercontent.com/-p2L5zKSs9Oc/AAAAAAAAAAI/AAAAAAAAAEE/PzwO-PqNro8/s64/photo.jpg",
      "userId": "16421844834226782203"
     },
     "user_tz": 120
    },
    "id": "rx8QHLaNWgdn",
    "outputId": "867d28f2-de4e-4807-93bc-3d96e3bdb6d0"
   },
   "outputs": [],
   "source": [
    "a = (model.predict(x_test, batch_size=batch_size) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1.........: 0.908665\n",
      "Precision..: 0.909269\n",
      "Recall.....: 0.909269\n",
      "Accuracy...: 0.908665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "print(\"F1.........: %f\" %(f1_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Precision..: %f\" %(precision_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Recall.....: %f\" %(recall_score(y_test, y_pred, average=\"macro\")))\n",
    "print(\"Accuracy...: %f\" %(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197  22]\n",
      " [ 12 196]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "labels = [0, 1]\n",
    "cm = metrics.confusion_matrix(y_test, y_pred, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.658     0.510     0.575       204\n",
      "           1      0.628     0.758     0.687       223\n",
      "\n",
      "    accuracy                          0.639       427\n",
      "   macro avg      0.643     0.634     0.631       427\n",
      "weighted avg      0.643     0.639     0.633       427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, digits=3))\n",
    "val1 = 0.5\n",
    "val2 = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hash_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8f674bbed481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtweets1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hash_map' is not defined"
     ]
    }
   ],
   "source": [
    "x1 = preprocessing(\"I am going to punch the president\")\n",
    "x1 = [x1]\n",
    "y1 = tokenizer.texts_to_sequences(x1)\n",
    "tweets1 = sequence.pad_sequences(y1, maxlen=maxlen)\n",
    "print(hash_map[((model.predict(tweets1) > 0.5).astype(int))[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeted\n"
     ]
    }
   ],
   "source": [
    "x1 = preprocessing(\"i am going to build a wall for the immigrants and kill them\")\n",
    "x1 = [x1]\n",
    "y1 = tokenizer.texts_to_sequences(x1)\n",
    "tweets1 = sequence.pad_sequences(y1, maxlen=maxlen)\n",
    "print(hash_map[((model.predict(tweets1) > 0.5).astype(int))[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'data_format')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9cad2f930522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mdl_wts.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    315\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# in this case by convention `config` holds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2512\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 2500\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   2501\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;31m# in this case by convention `config` holds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;31m# the kwargs of the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \"\"\"\n\u001b[0;32m-> 1271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IRE_MP/venv/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'data_format')"
     ]
    }
   ],
   "source": [
    "model1 = load_model('.mdl_wts.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targeted\n"
     ]
    }
   ],
   "source": [
    "x1 = preprocessing(\"i am going to build a wall for mexicans and kill them\")\n",
    "x1 = [x1]\n",
    "y1 = tokenizer.texts_to_sequences(x1)\n",
    "tweets1 = sequence.pad_sequences(y1, maxlen=maxlen)\n",
    "if (model1.predict(tweets1) > 0.5).astype(int):\n",
    "    temp = (model.predict(tweets1) > 0.5).astype(int)\n",
    "    print(hash_map[temp[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_map = {0:'individual',1:'targeted'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'individual'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individual\n"
     ]
    }
   ],
   "source": [
    "x1 = preprocessing(\"i am going to kill you\")\n",
    "x1 = [x1]\n",
    "y1 = tokenizer.texts_to_sequences(x1)\n",
    "tweets1 = sequence.pad_sequences(y1, maxlen=maxlen)\n",
    "if (model1.predict(tweets1) > val1).astype(int):\n",
    "    temp = (model.predict(tweets1) > val2).astype(int)\n",
    "    print(hash_map[temp[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_en_a.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
